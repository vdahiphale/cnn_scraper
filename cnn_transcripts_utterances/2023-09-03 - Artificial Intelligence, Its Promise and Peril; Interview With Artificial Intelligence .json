{
  "date": "2023-09-03",
  "headline": "Fareed Zakaria GPS",
  "subHeadline": "Artificial Intelligence, Its Promise and Peril; Interview With Artificial Intelligence Pioneer Geoffrey Hinton; Interview With Academy Award-Winning Filmmaker James Cameron. Aired 10-11a ET",
  "utterances": [
    {
      "timeStamp": "10:00:21",
      "speaker": "FAREED ZAKARIA, CNN HOST",
      "sentences": "This is GPS, the GLOBAL PUBLIC SQUARE. Welcome to all of you in the United States and around the world. I'm Fareed Zakaria.(Voice-over): Today, a GPS special. \"Artificial Intelligence, Its Promise and Peril.\" We'll bring you an in-depth look at the brave and frightening new world that faces us all today.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "UNIDENTIFIED FEMALE",
      "sentences": "It's nice to meet you.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "ZAKARIA",
      "sentences": "Startling powers of this technology exploded into the public consciousness late last year.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "ABBY PHILLIP, CNN HOST",
      "sentences": "ChatGPT has basically exploded in popularity.SCOTT PELLEY, \"60 MINUTES\" HOST: Machines that could teach themselves super human skills.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "UNIDENTIFIED MALE",
      "sentences": "If this technology goes wrong, it can go quite wrong.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "UNIDENTIFIED MALE",
      "sentences": "ChatGPT.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "UNIDENTIFIED FEMALE",
      "sentences": "ChatGPT.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "UNIDENTIFIED FEMALE",
      "sentences": "ChatGPT.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "ZAKARIA",
      "sentences": "We start with a look at the past, the present and the unknown future of artificial intelligence with Eric Schmidt, the former CEO and chair of Google who has long been interested in AI.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "ERIC SCHMIDT, FORMER EXECUTIVE CHAIRMAN AND CEO, GOOGLE",
      "sentences": "So what happens if it can build a pathogen and it ends up in the hands of an Osama bin Laden type of person and that pathogen can kill a million people?",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "ZAKARIA",
      "sentences": "Then the absolute worst-case scenario. AI run amok. The extinction of us all. The human race, that is. I'll talk to a man known as the godfather of AI who left a top job in tech so he could warn us of the risks.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "GEOFFREY HINTON, ARTIFICIAL INTELLIGENCE PIONEER",
      "sentences": "And then there's the problem of if these things get smarter than us, which I believe they will, then the question is, will we be able to control it?",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "ZAKARIA",
      "sentences": "On the flipside the beauty of what AI can help humans create. James Cameron made his AI inspired \"Terminator\" films long before artificial intelligence became a buzzword. Now he uses AI to make his new productions ever better. He'll explain how it all works.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "JAMES CAMERON, FILMMAKER",
      "sentences": "We're taking an accurate performance and translating it onto a CG character and we want it to be as accurate as possible but I think where it's going really feeds into one of our greatest social ills right now which is that we can't trust what we see.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "ZAKARIA",
      "sentences": "Then, an unusual fascinating application of AI. I've been mesmerized by a piece of artificial intelligence artwork at New York's Museum of Modern Art. A human artist fed the computer data from 200 years of paintings, drawings, sculptures and more from the museum's collections. And this is the ever-evolving result. I'll talk to the human beings behind the work.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "UNIDENTIFIED MALE",
      "sentences": "Art will be for anyone, any culture, any background. But I'm trying to find this language of humanity.ZAKARIA (on-camera): And let's get started. In 1945, the brilliant computer scientist Allen Turin wrote that computers would someday be able to play very good chess. The term artificial intelligence hadn't even been coined yet. That would take another decade. Today the Oxford English dictionary defines AI as the capacity of computers or other machines to exhibit or simulate intelligent behavior. And in the meantime Turin's prophecy has come true, and then some. In 1997, IBM supercomputer Deep Blue beat the then world chess champion Garrick Kasparov in a six-game match. 20 years later, in 2017, Google's Alfa Go beat the world's number one player of Go, an even more complex board game to master especially for a computer. But it's not all fun or games. The meteoric rise of ChatGPT and other AI programs in recent months has shown us that AI can pass graduate level exams, get a top 10 percent score on the bar exam, write legal briefs, find cancerous growths better than radiologists, and much more. I wanted Eric Schmidt to help us understand it all better. The former Google CEO and chairman joined forces with the legendary diplomat Henry Kissinger and the MIT computer scientist Daniel Huttenlocher to write a book titled \"The Age of AI and Our Human Future.\" He's also been working to keep America at the forefront of the field by serving as chairman of the National Security Commission on Artificial Intelligence. I should note I'm a senior adviser at Schmidt Futures, his philanthropic initiative. To begin, I wanted to understand what the next few years could bring for AI applications. [10:05:02] SCHMIDT: Many people believe the computer will be able to recursively self-improve. In other words it'll start to get better on its own. That's a very, very big change in history. Up until now, the tools that we as humans have built have been under our control. Maybe poorly but they have been under our control. There is a point many people think that it will be within the next four to five years, some people think sooner, some people later, I think maybe five years, where the system will be able to learn something new and act on it. This is called tool use. There is indeed a paper from Deep Mine recently on extreme risks and it goes through some speculation of what would happen. Imagine if one of these things learns how to get access to weapons. Clearly we don't want that.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "ZAKARIA",
      "sentences": "Right. So the canonical example that people use when talking about the dangers of AI is you tell the machine to make paper clips and it says sure and it makes paper clips and runs out of material to make paper clips with and then it starts turning other things into material that can make paper clips. And evenly runs out of that and then it starts using human beings and killing human beings because it is trying to just fulfill this one objective.How -- is that too simplistic? How should we think about this?",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "SCHMIDT",
      "sentences": "It's an easy example of how you can make a mistake. And those are called wrong objective function. So the way you would actually, through the paper clip example, you could say here are some rules. You can't use more energy than is available to you. You can't harm any people. You have to make money, and by the way, we want you with those constraints to make as many paper clips as possible.Now in human society, you start to think about all the rules you as a human, you have to behave, there are these laws, there are all these cultural laws, you have to use language, you have to stay within the limits of human behavior. One way to think about it is it's a constitution. So one company, this is Anthropic, decided to write a constitution for the system, wrote its own view of what constitution life should be, and fed it in. So there are ideas about essentially limiting either the knowledge or behavior of these models to keep them in a human space. I'll give you another example. Imagine you go and you say to the computer, and this is when it can recursively self-improve, this is maybe -- this is speculation maybe five years from now, you say work really hard, start right now, learn everything. And it goes through French and it goes through biology and it goes through science and so forth. And at some point it starts asking itself questions it doesn't know the answer so it starts e-mailing physics professors and things like that. No problem. And then it realizes it needs more power so it steals the power from the hospital next door. So, you know, all of these cases, there's an implied permission set which has to be written down and controlled.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "ZAKARIA",
      "sentences": "How would you respond to somebody who says, look, if AI is so great, how come we still don't have self-driving cars? There are -- things can be very much more complicated than they look to actually execute.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "SCHMIDT",
      "sentences": "The examples that we're celebrating right now all have errors in them. The fact that a reporter had the computer fall in love with him and convince him to leave his wife for the computer is very humorous. Right. No one died in that scenario. And by the way, he didn't leave his wife for the computer so we're clear. Anything involving human health is very different. Right. You want a human flying the airplane, watching the auto pilot.It's going to be a while before we have universally self-driving cars. It's just a really hard problem especially because of the mixing. But it's not because we don't know how to do it. It's because of the tolerance for risk, its --",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "ZAKARIA",
      "sentences": "The error rate has to be close to zero.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "SCHMIDT",
      "sentences": "It has to be really low.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:00:21",
      "speaker": "ZAKARIA",
      "sentences": "What are you worried the most about? I mean, I've heard people talk about the dangers of AI in war. I've heard people talk about the dangers of AI in medicine. When you think about it, for you, what's the scary part?",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:10:07",
      "speaker": "ZAKARIA",
      "sentences": "Next on GPS, more with Eric Schmidt. I'll ask him to explain how exactly he would rein in AI. Can you do it? His answer, when we return.(COMMERCIAL BREAK)",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:15:01",
      "speaker": "SCHMIDT",
      "sentences": "I am concerned about the extreme risk that is extreme or existential risk of this. I'm concerned that they have polymathic capabilities that will allow somebody who does not have a PhD in biology and who is evil to do something that could really harm people. That's my primary concern.There are plenty of other things to complain about. The copyright issue, misinformation, the dog ate the homework kinds of problems. These are real people's problems that they're concerned about. But those are not extreme risks. They won't hurt 10,000, 20,000 or 30,000 people. I think primarily the initial threats are in biology and cyber. Eventually, and of course misinformation and so forth. Eventually we're going to have a situation where these systems do what is called step wise refinement. So basically they can say -- they can't do this now. They say here are the steps to build a recipe. Here's the steps to solve a problem. Here's the steps to build a bomb. At the point of which it could do steps, each step it's doing a little bit of thinking. Not our kind of thinking, but its own to choose the next step. That's the beginning of consciousness. At the point at which those steps are put together, you're going to have super intelligence. There is a scenario, many people believe, where once you have one super intelligence, it could find the others. And in that scenario, it can develop the ability to speak to itself in a language we can't understand. That is unchartered territory in humanity and we need to prevent that.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:15:01",
      "speaker": "ZAKARIA",
      "sentences": "Do we have the ability to put into this constitution or software architecture essentially a kill switch? Or is the 2001 \"Space Odyssey\" scenario correct which is that the computer will figure out a way to override the kill switch.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:15:01",
      "speaker": "SCHMIDT",
      "sentences": "You can always unplug them. The standard joke is, at the end of the day, this thing can be doing whatever it's doing and there's going to be a guard with a machine gun to protect the computer and another guard who has only one function, which is to turn it off on command from the president. And that's probably the eventual state.There is good news before everyone gets too worried about this. The kind of damage that I'm talking about will be done by large teams in very large systems. There won't be very many of them. So my own view is that the militaries and national security around the world will be monitoring them. Today if you launch a missile of any kind, you know, a satellite or what have you, there is a process to let every government in the know that it's going to happen because that way they know you're not launching a deadly missile, a satellite or what have you. And then they use that information to tune their observations systems. You'll see something similar. That these unfettered systems that are so powerful, unmanaged, unmonitored, will be too dangerous without the monitoring.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:15:01",
      "speaker": "ZAKARIA",
      "sentences": "So in a sense, what you're describing is just as we developed a kind of framework of controls for nuclear weapons, and the president having that ultimate control with the football, there may be a second football as it were, a second set of constraints, this time on artificial intelligence?",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:15:01",
      "speaker": "SCHMIDT",
      "sentences": "There will be an internet monitoring group in every country and it will be monitoring for these things. There are many people who believe that the only way to fight AI offensively is defensively because they're so fast, so you can imagine lots of defensive network systems that are watching for this, making sure there's nothing awry and responding very quickly. You could imagine an automated kill switch in that moment because turning it off is not necessarily offensive work.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:15:01",
      "speaker": "ZAKARIA",
      "sentences": "Does this leave you excited or scared?",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:15:01",
      "speaker": "SCHMIDT",
      "sentences": "I forgot to say the most important thing. Can you imagine the development of an AI doctor for the world? An AI tutor for every person in the world? Can you imagine solving every problem in plastics, materials, science, power, energy density, solving climate change? The overwhelming benefit of intelligence, we need to get there and not kill ourselves in the process.But I want the benefits. I think that society will be so much richer, so much better educated, so much more powerful as humans because of these tools. We just have to make sure that these edge conditions such as the extreme risks are kept under control.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:15:01",
      "speaker": "ZAKARIA",
      "sentences": "Eric Schmidt, a pleasure.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:15:01",
      "speaker": "SCHMIDT",
      "sentences": "Thank you.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:25:06",
      "speaker": "HINTON",
      "sentences": "Thank you.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:25:06",
      "speaker": "ZAKARIA",
      "sentences": "When did you start to go from being exhilarated about all this to worrying?",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:25:06",
      "speaker": "HINTON",
      "sentences": "Really only a few months ago. So I -- I mean, I was always worried about things like, what would happen to the people whose jobs were lost to an AI? And would there be battle robots? And what about all the fake news it was going to produce? And what about the eco chambers being produced by getting people to click on things that make them indignant?All those worries I was worried about. But the idea that this stuff will get smarter than us and might actually replace us, I only got worried about a few months ago when I suddenly flipped my view. My view had been that I'm working on trying to make digital intelligence by trying to make it like the brain. And I assume the brain is better. We're just trying to sort of catch up with the brain. I suddenly realized maybe the algorithm we brought is actually better than the brain already. And when we scale it up, we'll get things smarter than us.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:25:06",
      "speaker": "ZAKARIA",
      "sentences": "So when you think about, you know, the concerns about AI, how would you describe them very simply to somebody? What is it that you worry about?",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:25:06",
      "speaker": "HINTON",
      "sentences": "So I would distinguish a bunch of different concerns. So it's what I call the existential threat which is about whether they will wipe out humanity. That's definitely a threat to humanity's existence. The other threats aren't existential in the same sense but it's existential however used. They are very bad like they'll make a lot of jobs much more efficient by getting chatbots to do it instead of people.There'll be a huge increase in productivity and the big worry is that huge increase in productivity which should be good for us will cause the rich to get richer and the poor to get poorer, and that's going to be very bad for society. Then these things like battle robots where obviously defense departments would like to have robots that replace soldiers. That's going to make it politically much easier to start wars. Those fake news, where it's going to be very hard to know what's true. And there's the division into these warring camps by the big companies trying to get you to click on stuff that will make you indignant and so you get these two different eco chambers.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:25:06",
      "speaker": "ZAKARIA",
      "sentences": "And these are the small problems.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:25:06",
      "speaker": "HINTON",
      "sentences": "Those are the small problems. Those are more immediate and they're not small problems at all. They're huge problems but they don't involve the end of humanity. So I don't call them existential. And then there is the problem of if these things get smarter than us, which I believe they will, and many areas, and I begin to believe they will and in not too long, like in, you know, not in 100 years.So I wish we had a simple solution. Like with climate change, there is a simple solution. You stop burning carbon and it will take a while but you'll end up OK. And it's politically unpalatable for the oil companies. But if you stop burning carbon, you'd solve the problem. Here there isn't anything like that. The best people can come up with, I think, is that you try and give these things strong ethics. The one advantage we have is that they didn't evolve. We made them. We evolved and we evolved in small warring tribes of hominins, we wiped out 21 other different species of hominins because we're very competitive and aggressive, and these things don't have to be like that. We're creating them. Maybe we could build them with strong ethical principles wired in.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:25:06",
      "speaker": "ZAKARIA",
      "sentences": "And you could do that with the algorithms? Because I noticed --",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:25:06",
      "speaker": "HINTON",
      "sentences": "Maybe.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:25:06",
      "speaker": "ZAKARIA",
      "sentences": "I notice when you ask ChatGPT a question, say about homosexuality, it gives an answer that is clearly curated in a way to be thoughtful, to be, you know, not to reflect every crazy view about it. But, you know, kind of -- politically correct may be too strong but it's a sensitive answer.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:25:06",
      "speaker": "HINTON",
      "sentences": "Yes.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:25:06",
      "speaker": "ZAKARIA",
      "sentences": "So there is some shaping that takes place. If you ask it how do you build a nuclear weapon, it says I won't tell you that.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:30:27",
      "speaker": "ZAKARIA",
      "sentences": "All right. Well, such a pleasure.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:30:27",
      "speaker": "HINTON",
      "sentences": "Thank you.(END VIDEOTAPE)",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:30:27",
      "speaker": "ZAKARIA",
      "sentences": "Next on GPS, how will artificial intelligence change the way movies are made? Well, I'll ask the great director James Cameron of \"Avatar\" fame next.(COMMERCIAL BREAK)",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "ZAKARIA",
      "sentences": "So, when you look at all this technology, because you're so immersed in it, does it excite you, does it scare you?",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "CAMERON",
      "sentences": "I'd say right now I'm a little more scared than I am excited. We've used a lot of smaller A.I. tools very specifically targeted in the development of our avatar process to speed up our work flow and increase the accuracy of our facial pipeline because we're taking an actor's performance and translating it on to a C.G. character and we want it to be as accurate as possible.But I think where it's going really feeds into one of our greatest social ills right now which is that we can't trust what we see. You know, with deepfakes and so on and now with the chatbots we won't be able to trust our sources as much. But it's going to get harder and harder and harder as we go along because you'll actually see a piece of video that looks completely compelling and you can't believe it. So now unless you're physically present, how do you know that you're not being -- you know, it becomes this kind of phenomenon -- logical crisis, right? I mean, you know, that the -- Socrates and -- you know, always said that, you know, we're in the back of a cave and we're seeing only the shadow of that which is real. And I think that's where we're going. We won't know if our feeds are accurate.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "ZAKARIA",
      "sentences": "I mean, to me, you know, Henry Kissinger and Eric Schmidt wrote this book about A.I. One of the most haunting parts is it talks about how, you know, the renaissance and the enlightenment really the enlightenment allowed human beings to use their reason --",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "CAMERON",
      "sentences": "Yes.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "ZAKARIA",
      "sentences": "-- and to dispelled what was before kind of myth making --",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "CAMERON",
      "sentences": "Yes.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "ZAKARIA",
      "sentences": "-- and fantasy. And so, when you look at a phenomenon like the sun rising, people used to say, well, that's the sun god --",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "CAMERON",
      "sentences": "Yes, sure. The chariot of the sun, right?",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "ZAKARIA",
      "sentences": "-- going across the sun. And then reason took over and we were like, no, we can understand why this happened.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "CAMERON",
      "sentences": "Yes.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "ZAKARIA",
      "sentences": "With A.I., we're almost going back to that world where we know the answer but we don't know why it's the answer.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "CAMERON",
      "sentences": "That's right.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "ZAKARIA",
      "sentences": "So, the computer will tell you have the answer.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "CAMERON",
      "sentences": "Yes. And it can't tell you. It can't tell you.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "ZAKARIA",
      "sentences": "And it can't tell you. Right. And so, we're -- we used to trust religion.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "CAMERON",
      "sentences": "Yes.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "ZAKARIA",
      "sentences": "Now we trust -- we will end up trusting A.I.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "CAMERON",
      "sentences": "That's right.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "ZAKARIA",
      "sentences": "We no longer will trust human reason --",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "CAMERON",
      "sentences": "That's right.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "ZAKARIA",
      "sentences": "-- because we know how limited it is. CAMERONWell, I don't think an AGI, a superintelligent AGI, would need to use nuclear weapons. In fact, it wouldn't want to. This electromagnetic pulse would wipe out too much of its own electronic infrastructure. I think it would do exactly what's happening right now. Get us addicted to our devices. Every phone that we -- first of all, if you look around anywhere, everybody is always on their phone. So, the cat has been belled, right, and they -- and so this is just handing the keys in my mind to a techno dictatorship or authoritarian regime of some kind which could easily be run by a super computer to its ends. And so, I see us in a new arms race. Whoever gets to that superintelligence first will have world dominance and that's what Putin has said. He was actually quoted as saying that as you reported.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "ZAKARIA",
      "sentences": "But -- and what I'm -- so the way you see it happening, this is fascinating, is now, you know, you don't need to conquer people physically.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "CAMERON",
      "sentences": "Yes.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "ZAKARIA",
      "sentences": "You conquer them mentally.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "CAMERON",
      "sentences": "Exactly.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "ZAKARIA",
      "sentences": "You trap them mentally.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "CAMERON",
      "sentences": "Yes. Just look around. In fact, I was -- I was, you know, in a speaking engagement the other day and when asked this sort of question, I ended with, now, how do we know it hasn't already happened?From sitting here and observing the world, nothing that's happening out there makes a whole lot of sense to me right now. How do we know we're not being manipulated by an emergent AGI that's already been developed? We wouldn't know. You know, because it's --",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:35:00",
      "speaker": "ZAKARIA",
      "sentences": "We may be -- we may be in a simulation.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:40:00",
      "speaker": "ZAKARIA",
      "sentences": "Right, right.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:40:00",
      "speaker": "CAMERON",
      "sentences": "Yes. Although it seems pretty good.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:40:00",
      "speaker": "ZAKARIA",
      "sentences": "So where is the optimistic part? You said that you -- you know, you go between both. Is there a part of you that says, well, this is -- you know, AGI is going to cure cancer and all of that? CAMERON",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:40:00",
      "speaker": "ZAKARIA",
      "sentences": "We should explain. A.I. is artificial intelligence.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:40:00",
      "speaker": "CAMERON",
      "sentences": "Right.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:40:00",
      "speaker": "ZAKARIA",
      "sentences": "AGI is artificial general intelligence which is kind of like --",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:40:00",
      "speaker": "CAMERON",
      "sentences": "Which we don't --",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:40:00",
      "speaker": "ZAKARIA",
      "sentences": "-- superintelligence.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:40:00",
      "speaker": "CAMERON",
      "sentences": "Yes.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:40:00",
      "speaker": "ZAKARIA",
      "sentences": "We still haven't gotten.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:40:00",
      "speaker": "CAMERON",
      "sentences": "We think we don't have it yet. We probably don't, you know? I mean, I talk to a lot of people in A.I. and that does scare me. Because to me nothing that we've done that's really transformative technology has not already been weaponized as we saw with, you know, nuclear energy and all of that.But in terms of A.I., it is very powerful. You know, they've done -- they've done studies, obviously, where they compare a panel of doctors analyzing scans to an A.I. that's trained to identify tumors and things like that. The A.I. scores better. So, in some of these tasks of looking at very large data sets and coming to the right analytic conclusion, they're better than us at that. And we should rely on them there. But they should be these separated tools. The second we start with these integrated systems and become too reliant, it will become a new religion.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:40:00",
      "speaker": "ZAKARIA",
      "sentences": "It will become like \"2001 Space Odyssey.\"HALL 9000, FICTIONAL CHARACTER: This mission is too important for me to allow you to jeopardize it.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:40:00",
      "speaker": "CAMERON",
      "sentences": "Yes. Right. Exactly.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:40:00",
      "speaker": "ZAKARIA",
      "sentences": "When you try to turn it off it doesn't.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:40:00",
      "speaker": "CAMERON",
      "sentences": "Yes. And you might find yourself locked out of the spaceship.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:40:00",
      "speaker": "DAVE BOWMAN, FICTIONAL CHARACTER",
      "sentences": "Do you read me HAL?HAL 9000: Affirmative, Dave.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:40:00",
      "speaker": "ZAKARIA",
      "sentences": "James Cameron, a pleasure to have you on.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:46:08",
      "speaker": "ZAKARIA",
      "sentences": "You are looking at the oldest known figurative painting in the world. Located in a cave on an Indonesian island, this pig painted with red ocher pigment is estimated to be at least 45,500 years old.Painting has come a long way since the days of cave art. In fact, my next guest uses no physical paint at all. No ochers or oils or water colors or acrylics. He paints with data. Turkish born artist Refik Anadol set out to answer the question, what would a machine dream about if it could see a museum's art collection? The result is \"Unsupervised,\" a 24-foot by 24-foot installation that dominates the lobby of the Museum of Modern Art in New York. This dream like imagery is being generated using artificial intelligence. Anadol trained the A.I. model using data from more than 200 years' worth of MoMA's art collection, which included nearly 90,000 works of art from over 26,000 artists. It is always learning and changing. Imagining art that could have existed in the collection as well as new art of the future. If you watch forever, you would not see the same screen twice. I sat down with Anadol and the museum's curator of paintings and sculpture Michelle Kuo to discuss this extraordinary work and the future of art and artificial intelligence. (BEGIN VIDEOTAPE)",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:46:08",
      "speaker": "ZAKARIA",
      "sentences": "Thank you both for joining us.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:46:08",
      "speaker": "REFIK ANADOL, DIRECTOR, REFIK ANADOL STUDIO",
      "sentences": "Thank you.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:46:08",
      "speaker": "MICHELLE KUO, CURATOR OF PAINTING AND SCULPTURE",
      "sentences": "Thank you.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:46:08",
      "speaker": "ZAKARIA",
      "sentences": "So, Refik, if somebody were to ask you just very simply, what is this? What would your answer be?",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:46:08",
      "speaker": "ANADOL",
      "sentences": "Yes. So, this is an A.I. data sculpture running real time by using for me the most inspiring art collection of humanity, MoMA's art works and their metadata. And A.I. real time dreaming or hallucinating, art works that doesn't exist but may exist.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:46:08",
      "speaker": "ZAKARIA",
      "sentences": "And to me the most interesting thing is that what you see on the screen second by second is a new image.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:46:08",
      "speaker": "ANADOL",
      "sentences": "Yes.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:46:08",
      "speaker": "ZAKARIA",
      "sentences": "It never repeats. ANADOL",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:46:08",
      "speaker": "ZAKARIA",
      "sentences": "How long can that go on?",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:46:08",
      "speaker": "ANADOL",
      "sentences": "As long as the museum and the people here together, it will go --",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:46:08",
      "speaker": "ZAKARIA",
      "sentences": "If we kept this on for 100 years there would never be a repetition.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:46:08",
      "speaker": "ANADOL",
      "sentences": "Yes.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:46:08",
      "speaker": "ZAKARIA",
      "sentences": "To me, what is fascinating about this, Refik, is that you fed in all these images but unlike the way we think of these images, there is no hierarchy. The computer does not know that the Picassos are supposed to be the most famous and the most expensive in the collection. Do you think in a sense this is -- you know, this kind of -- it shatters the hierarchy of art?",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:50:00",
      "speaker": "ZAKARIA",
      "sentences": "Do you think that there is a copyright or borrowing problem which is -- Michelle, when you look at this, there must be artists who still have copyright for their work. Is there a problem in any way with feeding it all this art?",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:50:00",
      "speaker": "KUO",
      "sentences": "In this case this is completely new what you're seeing. Refik and his team created this machine learning model. So, everything that's sort of falling from that -- following from that is a human creation in tandem with this complex machine learning model they've created.And so, what happens is it's really designed to steer as far away as possible from ever exactly recreating any specific work that exists in history. Even if it wanted to do that, I don't think A.I. is good enough to do that at this point. But this is steering away --",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:50:00",
      "speaker": "ZAKARIA",
      "sentences": "People refer to ChatGPT as sort of essentially very elaborate cut and paste. And is this like that?",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:50:00",
      "speaker": "KUO",
      "sentences": "This is not. It is actually not only different in degree but in kind. So, the best way to think about it almost is that this complex machine learning model that Refik's team has built has learned and learned and learned.Imagine if you just as a superhuman learned and learned and learned about hundreds of thousands of art works in MoMA's collection for quite some time and then you built your own map, maybe your own even imaginary museum of all these different works. You decided to put some of the works over here together, other works over here together.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:50:00",
      "speaker": "ZAKARIA",
      "sentences": "Right, right.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:50:00",
      "speaker": "KUO",
      "sentences": "And then you're wondering around that imaginary museum and saying, oh, well, there's a gap here. There's emptiness between these works that actually exist. So, what could exist there? And that is what this is constantly creating. So, in each step of the way, it is doing something new and not replicative and it's actually kind of the farthest actually you could get from a kind of cut and paste.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:50:00",
      "speaker": "ZAKARIA",
      "sentences": "Michell, do you think this is the future of art?",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:50:00",
      "speaker": "KUO",
      "sentences": "I think it's one future of art. And, I think, it's actually a kind of fascinating experiment that is really the beginning of something. It's not resolved. It's not the end or conclusion of something.I think it's -- it's an experiment in every sense of the word and that's something that we really try to support artists in doing. Because so many works and artists in the history of modern art, for example, were devoted to abstraction, to abstract art, to not depicting the world as it is in a kind of realistic or photographic way but to speculate about forms and shapes that don't exist in the real world. This, to my mind, is squarely in line with those kinds of experiments.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:50:00",
      "speaker": "ZAKARIA",
      "sentences": "Do you worry, Michelle, that it's -- it's art we can't explain? You know, it comes out of a black box and that the future of the black box will get even more complex and more mysterious to us in a sense. KUOAnd I think, you know, one thing that always resonates is at the beginning of photography, the camera was called the pencil of nature. Literally that there would be some other entity that's not human, that's controlling the images that you see. And yet we all know that that pencil of nature, which is also involving a machine, a tool, has become one of the most incredible devices for artists and for humans to use. So, that is just something that I think really allows us to get past, I think, knee-jerk kind of reactions of either fear or euphoria. It allows us to actually, you know, get in there and confront what is the complexity that is -- that is all around us right now and what do we have to do to understand it.",
      "isLastSentenceInterrupted": false
    },
    {
      "timeStamp": "10:50:00",
      "speaker": "ZAKARIA",
      "sentences": "Michelle, Refik, thank you so much.(END VIDEOTAPE)",
      "isLastSentenceInterrupted": false
    }
  ]
}